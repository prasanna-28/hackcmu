\documentclass[12pt,a4paper]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{geometry}

\geometry{margin=1in}

\begin{document}

\section{Inverse Matrices}

An \textit{inverse matrix} is invertible if there is a matrix $A^{-1}$ such that $AA^{-1} = A^{-1}A = I$.

\subsection{Examples}

\begin{itemize}
    \item $A = \begin{bmatrix} 3 & 1 \\ 1 & 2 \end{bmatrix}$, $B = \begin{bmatrix} 2 & -1 \\ -1 & 3/2 \end{bmatrix}$ are inverses
    \item Since $AB = \begin{bmatrix} 1 & 0 \\ 0 & 1 \end{bmatrix}$, we can write $B = A^{-1}$
    \item Not all matrices have inverses. $A = \begin{bmatrix} 1 & 2 \\ 2 & 4 \end{bmatrix}$ has no inverse
\end{itemize}

\subsection{Connection to Linear Transformations}

If $T$ is a linear transformation with associated matrix $A$ (so $T(x) = Ax$), then the inverse transformation exists when $A^{-1}$ exists.

\section{2x2 Inverse Formula}

Let $A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}$. Then if $ad-bc \neq 0$:

\[A^{-1} = \frac{1}{ad-bc} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}\]

This is a special case of Cramer's formula (which is complicated to compute but has the same form for nxn matrices).

\subsection{Using Cross-Section to Find the Inverse}

Suppose $A$ has inverse $A^{-1}$.
Then $AA^{-1} = [A_1, A_2] = I$

So $A_1 = \begin{bmatrix} 1 \\ 0 \end{bmatrix}$ and $A_2 = \begin{bmatrix} 0 \\ 1 \end{bmatrix}$

To find $A^{-1}$, we must solve the system $Ax = e_i$ for each column vector.

Instead of solving $[A|e_1], [A|e_2], \ldots, [A|e_n]$ individually, we can solve $[A|I]$ at once.

\subsection{Gaussian Elimination Method}

If $A$ doesn't have n pivots (one in each row):
\begin{itemize}
    \item $A^{-1}$ does not exist
    \item $A$ is not invertible
\end{itemize}

If $A$ has n pivots, then the algorithm produces $[I|A^{-1}]$.

\section{Example: Finding $A^{-1}$}

Find $A^{-1}$, if it exists:

\[A = \begin{bmatrix} 2 & 1 & 3 \\ 1 & 0 & 1 \\ 3 & 1 & 4 \end{bmatrix}\]

Solution steps:
\begin{align*}
    \begin{bmatrix} 2 & 1 & 3 & | & 1 & 0 & 0 \\ 1 & 0 & 1 & | & 0 & 1 & 0 \\ 3 & 1 & 4 & | & 0 & 0 & 1 \end{bmatrix}
    &\xrightarrow{R_2 - \frac{1}{2}R_1}
    \begin{bmatrix} 2 & 1 & 3 & | & 1 & 0 & 0 \\ 0 & -\frac{1}{2} & -\frac{1}{2} & | & -\frac{1}{2} & 1 & 0 \\ 3 & 1 & 4 & | & 0 & 0 & 1 \end{bmatrix} \\
    &\xrightarrow{R_3 - \frac{3}{2}R_1}
    \begin{bmatrix} 2 & 1 & 3 & | & 1 & 0 & 0 \\ 0 & -\frac{1}{2} & -\frac{1}{2} & | & -\frac{1}{2} & 1 & 0 \\ 0 & -\frac{1}{2} & -\frac{1}{2} & | & -\frac{3}{2} & 0 & 1 \end{bmatrix} \\
    &\xrightarrow{R_3 - R_2}
    \begin{bmatrix} 2 & 1 & 3 & | & 1 & 0 & 0 \\ 0 & -\frac{1}{2} & -\frac{1}{2} & | & -\frac{1}{2} & 1 & 0 \\ 0 & 0 & 0 & | & -1 & -1 & 1 \end{bmatrix}
\end{align*}

Since $A$ doesn't have 3 pivots, $A^{-1}$ does not exist.

\section{Using Inverses to Solve Systems}

If $A$ exists, we can solve $Ax = b$ by multiplying both sides by $A^{-1}$:

\begin{align*}
    A^{-1}Ax &= A^{-1}b \\
    Ix &= A^{-1}b \\
    x &= A^{-1}b
\end{align*}

Note: $A^{-1}$ has a solution if $A$ is invertible (has n pivots). However, even if $A$ has n pivots, this solution is expensive to compute compared to Gaussian elimination.

\end{document}